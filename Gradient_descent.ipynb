{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradient(y_true: int, y_pred: float, x: np.array) -> np.array:\n",
        "    \"\"\"\n",
        "    y_true - истинное значение ответа для объекта x\n",
        "    y_pred - значение степени принадлежности объекта x классу 1, предсказанное нашей моделью\n",
        "    x - вектор признакового описания данного объекта\n",
        "\n",
        "    На выходе ожидается получить вектор частных производных H по параметрам модели, предсказавшей значение y_pred\n",
        "    Обратите внимание, что размерность этого градиента должна получиться на единицу больше размерности x засчет свободного коэффициента a0\n",
        "    \"\"\"\n",
        "    grad = x * ((1 - y_true) * y_pred - y_true * (1 - y_pred))\n",
        "    grad = np.append(grad, ((1 - y_true) * y_pred - y_true * (1 - y_pred)))\n",
        "    return grad\n",
        "\n",
        "\n",
        "# Функция обновления весов\n",
        "def update(alpha: np.array, gradient: np.array, lr: float):\n",
        "    \"\"\"\n",
        "    alpha: текущее приближения вектора параметров модели\n",
        "    gradient: посчитанный градиент по параметрам модели\n",
        "    lr: learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "    \"\"\"\n",
        "    alpha_new = alpha - gradient * lr\n",
        "    return alpha_new\n",
        "\n",
        "\n",
        "# функция тренировки модели\n",
        "def train(\n",
        "    alpha0: np.array, x_train: np.array, y_train: np.array, lr: float, num_epoch: int\n",
        "):\n",
        "    \"\"\"\n",
        "    alpha0 - начальное приближение параметров модели\n",
        "    x_train - матрица объект-признак обучающей выборки\n",
        "    y_train - верные ответы для обучающей выборки\n",
        "    lr - learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "    num_epoch - количество эпох обучения, то есть полных 'проходов' через весь датасет\n",
        "    \"\"\"\n",
        "    \n",
        "    alpha = alpha0.copy()\n",
        "    for epo in range(num_epoch):\n",
        "        for i, x in enumerate(x_train):\n",
        "\n",
        "            x_sigma = np.dot(x, alpha[:len(alpha) - 1]) + alpha[len(alpha) - 1]\n",
        "            sigma = 1 / (1 +  np.exp(- x_sigma))\n",
        "            alpha = update(alpha, gradient(y_train[i], sigma, x), lr)\n",
        "\n",
        "    return alpha"
      ],
      "metadata": {
        "id": "CCM4EIh_d8-n"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}